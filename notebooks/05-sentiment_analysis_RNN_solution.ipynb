{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with an RNN using Word Embedding\n",
    "\n",
    "The following implements word embedding to learn the sentiment (positive or negative) or movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# DON'T MODIFY THIS CELL\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "\n",
    "# import some modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T MODIFY THIS CELL\n",
    "\n",
    "# import the data\n",
    "reviews_url = 'https://raw.githubusercontent.com/prof-groff/deep-learning/master/data/sentiment/reviews.txt'\n",
    "labels_url = 'https://raw.githubusercontent.com/prof-groff/deep-learning/master/data/sentiment/labels.txt'\n",
    "reviews = requests.get(reviews_url).text\n",
    "labels = requests.get(labels_url).text\n",
    "\n",
    "# do some additional preprocessing\n",
    "reviews = re.sub(' br ','', reviews) # remove random remnants of <br> tags\n",
    "reviews = re.sub('\\n', 'newline_char', reviews) # temporarily remove \\n characters\n",
    "reviews = re.sub('\\s+', ' ', reviews) # remove all special characters and extra spaces\n",
    "reviews = re.sub('newline_char', '\\n', reviews) # replace the \\n characters\n",
    "\n",
    "# split the reviews and lables text at \\n characters to make lists\n",
    "reviews_list = reviews.split('\\n')[0:-1] # for some reason the last element is junk\n",
    "labels_list = labels.split('\\n')[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE\n",
      "\n",
      "\n",
      "this movie was the worst movie i have seen since date movie . i was laughing through out the whole movie instead of being scared . it was funny how the snakes would search for particular section of the passengers body to attack for example the eye the tongue the butt the breast . if we have seen national geographic channel we know snakes wont stay clinched on the body once they bite . for each particular scene the snakes would bite the passengers and would stay on the body biting the person . i believe the producer did not study his information on snakes and their behavior . i cant believe i wasted my money on this movie . so i don t recommend this movie trust just wait until it is at the dollar theatre or rent it . \n",
      "\n",
      "\n",
      "POSITIVE\n",
      "\n",
      "\n",
      " before sunrise is a wonderful love story and has to be among my top favorite movies ever . dialog and acting are great . i love the characters and their ideas and thoughts . of course the romantic vienna introduced in the movie does not exist you won t find a poet sitting by the river in the middle of the night and it isn t possible to get to all the places in only one night either especially if you re a stranger and it s your first night in vienna . but that s not the point . the relationship of the two characters is much more important and this part of the story is not at all unrealistic . although nothing ever really happens the movie never gets boring . the ending is genuinely sad without being titanic or something . even if you don t like love stories you should watch this film i m a little skeptic about the sequel that is going to be released in summer . the first part is perfect as it is in my opinion . \n"
     ]
    }
   ],
   "source": [
    "# DON'T MODIFY THIS CELL\n",
    "\n",
    "# look at an example negative and positive review\n",
    "print(labels_list[1001].upper())\n",
    "print('\\n')\n",
    "print(reviews_list[1001])\n",
    "print('\\n')\n",
    "print(labels_list[1002].upper())\n",
    "print('\\n')\n",
    "print(reviews_list[1002])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DON'T MODIFY THIS CELL\n",
    "\n",
    "# look at the distribution of review lengths (# of words)\n",
    "# some of the reviews are really long but most are under 500 words long\n",
    "review_lengths = []\n",
    "for each in reviews_list:\n",
    "    review_lengths.append(len(each.split()))\n",
    "\n",
    "plt.hist(review_lengths,bins=50)\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('review length')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL REVIEWS: 25000\n",
      "REVIEWS WITH < 300 WORDS: 18678\n"
     ]
    }
   ],
   "source": [
    "# TO-DO: PICK A MAX_LENGTH (AT LEAST 100) AND TRIM THE DATA TO ONLY THOSE REVIEWS \n",
    "# WITH NO MORE THAN THIS MANY WORDS\n",
    "max_length = 300\n",
    "\n",
    "# DO NOT MODIFY THIS CELL BELOW THIS POINT\n",
    "\n",
    "reviews_trimmed = []\n",
    "labels_trimmed = []\n",
    "\n",
    "for r, l in zip(reviews_list, labels_list):\n",
    "    if len(r.split())<= max_length:\n",
    "        reviews_trimmed.append(r)\n",
    "        labels_trimmed.append(l)\n",
    "        \n",
    "print('TOTAL REVIEWS: ' + str(len(reviews_list)))\n",
    "print('REVIEWS WITH < ' + str(max_length) + ' WORDS: ' + str(len(reviews_trimmed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB LENGTH: 53812\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "\n",
    "# determine the number of unique words in the reviews\n",
    "vocab = set(' '.join(reviews_trimmed).split())\n",
    "vocab_length = len(vocab)+1 # add one so zero is reserved for padding\n",
    "print('VOCAB LENGTH: ' + str(vocab_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "\n",
    "# a function to create mappings between words and integers\n",
    "# each integer is a key for each word and vice versa\n",
    "def create_lookup_tables(vocab):\n",
    "    # enumerate adds an index to each word in the vocab and returns a list of tuples\n",
    "    int_to_vocab = dict(enumerate(vocab, 1))\n",
    "    vocab_to_int = dict(zip(int_to_vocab.values(), int_to_vocab.keys()))\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "vocab_to_int, int_to_vocab = create_lookup_tables(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "\n",
    "# the following tokenizes the reviews and labels\n",
    "n_reviews = len(reviews_trimmed)\n",
    "reviews_vect = np.zeros([n_reviews, max_length])\n",
    "labels_vect = np.zeros([n_reviews,2])\n",
    "for ii, r, l in zip(np.arange(n_reviews), reviews_trimmed, labels_trimmed):\n",
    "    words = r.split()\n",
    "    n_words = len(words)\n",
    "    for jj, w in zip(np.arange(n_words), words):\n",
    "        reviews_vect[ii, max_length-n_words+jj] = vocab_to_int[w]\n",
    "    if l == 'positive':\n",
    "        labels_vect[ii,1]=1\n",
    "    else:\n",
    "        labels_vect[ii,0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n",
      "\n",
      "\n",
      "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life such as teachers . my years in the teaching profession lead me to believe that bromwell high s satire is much closer to reality than is teachers . the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn t \n",
      "\n",
      "\n",
      "[    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0. 31785. 43030. 20733. 45489. 38399.  2689.   537.\n",
      " 20735. 50797. 14955. 17277. 21601. 41175. 14952. 46002. 26883. 35654.\n",
      " 36862.  9921. 13859. 41356. 14952. 24135.   537. 23715.  1057. 20742.\n",
      " 17277. 46979.  4058. 53662. 34480. 28605. 35664. 44824. 31785. 43030.\n",
      "  1362.  2222. 20733.   539. 53437. 28605. 44479. 44836. 20733. 24135.\n",
      "   537. 17277.  1832. 28605. 41104. 13940. 17277.  8561. 21819. 12850.\n",
      " 31237. 15479. 41020.  8412. 39807. 22162. 24135.   375. 17277. 28303.\n",
      " 25153. 17277. 15519.  1423. 38630. 41012. 34480. 25153. 17277. 27122.\n",
      " 19907. 41567. 24771. 39807. 21819.   537. 10727. 19907. 41548. 17277.\n",
      " 13704. 20742. 39859. 45489. 25599. 52884. 45473. 28605. 20858.  7273.\n",
      " 17277.  9921. 19907. 33428. 33607.   537.   537.   537.   537.   537.\n",
      "   537.   537.   537.   537. 14955.   537.   537.   537.   537.   537.\n",
      "   537.   537.   537.   537.   537. 43030.   537. 45489. 20936. 15770.\n",
      " 50164. 19907. 34026. 40392. 28605.  3555.  1178. 25153. 45208. 24135.\n",
      "   537. 25599. 31058. 28605. 31785. 43030.   537. 19907. 38909. 44824.\n",
      " 28238. 19182. 25153. 23715. 42871. 34790. 44824. 31785. 43030. 20733.\n",
      " 52130. 51579.   537. 38694. 45489. 40837. 44824. 20735. 20442. 31781.]\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "\n",
    "# look at an example tokenized review\n",
    "\n",
    "print(labels_trimmed[0].upper())\n",
    "print('\\n')\n",
    "print(reviews_trimmed[0])\n",
    "print('\\n')\n",
    "print(reviews_vect[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: BREAK THE DATA INTO A TRAINING, VALIDATION, AND TESTING SETS \n",
    "# WITH AT LEAST 1000 ELEMENTS IN THE VALIDATION AND TESTING SETS\n",
    "val_size = 1000\n",
    "test_size = 1000\n",
    "\n",
    "# DO NOT MODIFY THIS CELL BELOW THIS POINT\n",
    "\n",
    "x_train, x_val, x_test = reviews_vect[:-(val_size+test_size)], reviews_vect[-(val_size+test_size):-test_size], reviews_vect[-test_size:]\n",
    "y_train, y_val, y_test = labels_vect[:-(val_size+test_size)], labels_vect[-(val_size+test_size):-test_size], labels_vect[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILD MODEL...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 256)          13775872  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 13,973,250\n",
      "Trainable params: 13,973,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "TRAIN...\n",
      "\n",
      "Train on 16678 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "16678/16678 [==============================] - 21s 1ms/step - loss: 0.6584 - acc: 0.6476 - val_loss: 0.5409 - val_acc: 0.7390\n",
      "1000/1000 [==============================] - 0s 378us/step\n",
      "\n",
      "TEST SCORE: 0.51607643699646\n",
      "TEST ACCURACY: 0.7689999980926514\n"
     ]
    }
   ],
   "source": [
    "# TO-DO: SELECT MODEL SIZE PARAMETERS\n",
    "embedding_size = 256\n",
    "memory_units = 128\n",
    "\n",
    "# TO-DO: SELECT HYPERPARAMETERS\n",
    "batch_size = 256\n",
    "epochs = 1\n",
    "learning_rate = 0.003\n",
    "\n",
    "# TO DO: BUILD A MODEL WITH EMBEDDING, ONE LSTM LAYER, AND ONE DENSE \n",
    "# OUTPUT LAYER WITH TWO OUTPUT UNITS\n",
    "print('build model...'.upper())\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length, output_dim=embedding_size, input_length=max_length))\n",
    "model.add(LSTM(memory_units, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=learning_rate)\n",
    "# ALTERNATIVE OPTIMIZER\n",
    "# optimizer = 'adam'\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "print('\\ntrain...\\n'.upper())\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('\\ntest score: '.upper() + str(score))\n",
    "print('test accuracy: '.upper() + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTING SENTIMENT OF FOLLOWING REVIEW...\n",
      "\n",
      "i just wondering what is the purpose of making movies like this the profit and to whom they are referring what intelligence must use your brain to watch something like this crap this movie is watchable by under years old children if you are adults don t try to watch it . thats the reason i think hollywood started to use cartoons in movies with actors like this you must forget the art of cinema be sure that you ll have tons of pop corn to consume for time to pass till this movie ends also get many cola s hamburgers your laptop your cellphone this movie can be used easily in a restaurant but for sure not in a theater my dog who is always next to my family when watching a movie left the building . the sure thing is that this movie is referring to people with no demands from the cinema art . the only thing that this movie can be used is for watching it when making the supermarket shopping list . i am giving stars for supporting the india s cinema efforts but for nothing more or less . .\n",
      "\n",
      "\n",
      "PASSING THE REVIEW THROUGH THE TRAINED MODEL...\n",
      "\n",
      "PREDICTED SENTIMENT - 0 - NEGATIVE, 1 - POSITIVE\n",
      "[0.7141943  0.28580564]\n",
      "NEGATIVE\n",
      "\n",
      "\n",
      "ACTUAL SENTIMENT\n",
      "NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "# TO-DO: PICK A TEST CASE\n",
    "# let's look at a specific review and compare the predicted sentiment to the actual sentiment\n",
    "\n",
    "test_case = 410 # index of one of the reviews in the test set\n",
    "\n",
    "# DO NOT MODIFY THIS CELL BELOW THIS POINT\n",
    "\n",
    "x = x_test[test_case]\n",
    "y = y_test[test_case]\n",
    "\n",
    "# convert from tokens back to text\n",
    "test_review = []\n",
    "for each in x:\n",
    "    if each != 0:\n",
    "        test_review.append(int_to_vocab[each])\n",
    "\n",
    "test_review = ' '.join(test_review)\n",
    "\n",
    "# look at an example negative and positive review\n",
    "print('predicting sentiment of following review...\\n'.upper())\n",
    "print(test_review)\n",
    "print('\\n')\n",
    "\n",
    "print('passing the review through the trained model...\\n'.upper())\n",
    "x = np.reshape(x, (1,len(x)))\n",
    "y_prime = model.predict(x)\n",
    "print('predicted sentiment - 0 - negative, 1 - positive'.upper())\n",
    "print(y_prime[0])\n",
    "print(['negative', 'positive'][np.argmax(y_prime[0])].upper())\n",
    "print('\\n')\n",
    "print('actual sentiment'.upper())\n",
    "print(['negative', 'positive'][np.argmax(y)].upper())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHALLENGE: WRITE YOUR OWN REVIEW AN USE THE MODEL TO PREDICT ITS SENTIMENT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
