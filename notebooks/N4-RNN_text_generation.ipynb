{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Text Generation\n",
    "\n",
    "This notebook implements a recurrent neural network that learns to compose sonnets after being trained by Shakespeare. A character level approach is used. Hidden layers use LSTM units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shakespeare's Sonnets or Frankenstein\n",
    "\n",
    "A previously processed text file containing all of Shakespeare's sonnets or the text of Frankenstein by Mary Shelley is imported. The character vocabulary and dictionaries to make characters to indexes and vice versa are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT LENGTH: 94687\n",
      "\n",
      "TEXT SAMPLE:\n",
      "\n",
      "i\n",
      "from fairest creatures we desire increase,\n",
      "that thereby beauty's rose might never die,\n",
      "but as the riper should by time decease,\n",
      "his tender heir might bear his memory:\n",
      "but thou, contracted to thine own bright eyes,\n",
      "feed'st thy light's flame with self-substantial fuel,\n",
      "making a famine where abundance lies,\n",
      "thy self thy foe, to thy sweet self too cruel:\n",
      "thou that art now the world's fresh ornament,\n",
      "and only herald to the gaudy spring,\n",
      "within thine own bud buriest thy content,\n",
      "and tender churl mak'st waste in niggarding:\n",
      "pity the world, or else this glutton be,\n",
      "to eat the world's due, by the grave and thee.\n"
     ]
    }
   ],
   "source": [
    "# read in preprocessed text of shakespeare's sonnets \n",
    "\n",
    "# from local file system\n",
    "# filename = 'sonnets.txt'\n",
    "# filename = 'frankenstein.txt'\n",
    "# file = open(filename,'r')\n",
    "# text = file.read()\n",
    "\n",
    "# from github\n",
    "url = 'https://raw.githubusercontent.com/prof-groff/deep-learning/master/data/sonnets.txt'\n",
    "# url = 'https://raw.githubusercontent.com/prof-groff/deep-learning/master/data/frankenstein.txt'\n",
    "text = requests.get(url).text\n",
    "\n",
    "len_text = len(text)\n",
    "print('text length: '.upper() + str(len(text)) + '\\n')\n",
    "print('text sample:'.upper() + '\\n')\n",
    "print(text[0:612]) # show some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 38\n"
     ]
    }
   ],
   "source": [
    "# created some dictionaries\n",
    "chars = sorted(list(set(text)))\n",
    "len_chars = len(chars)\n",
    "print('total chars: ' + str(len_chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text is chunked up into sequences of uniform length. Each sequence is a feature and has a target corresponding to the character in the text immediately following the sequence. The features and targets are then vectorized. Each character is converted to a Boolean vectors having only one true element at the possiton corresponding to the character. <em>Note: making these vectorized features and targets integers (0s and 1s) instead of booleans seriously hampers learning and I am not sure why.</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF FEATURES (SEQUENCES):31520\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "seq_length = 128\n",
    "step = 3\n",
    "features = []\n",
    "targets = []\n",
    "for i in range(0, len_text - seq_length, step):\n",
    "    features.append(text[i: i + seq_length])\n",
    "    targets.append(text[i + seq_length])\n",
    "num_features = len(features)\n",
    "print('number of features (sequences):'.upper() + str(num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((num_features, seq_length, len_chars), dtype=np.bool)\n",
    "y = np.zeros((num_features, len_chars), dtype=np.bool)\n",
    "for i, feature in enumerate(features):\n",
    "    for t, char in enumerate(feature):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[targets[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model Graphs\n",
    "\n",
    "Two RNN graphs are implemented here. One is more deep and less wide and the other is less deep and more wide. The model parameters have been tuned to give decent results. A function is also defined to allow sampling of the train modeled in order to generate new character sequences. In additoin, a function is defined which is called at the end of each epoch to generate and display generated character sequences as the network learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(seq_length, n_chars):\n",
    "    print('buildinng two-layer model with 128 memory units...'.upper()+'\\n')\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=(seq_length, n_chars)))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "    optimizer = RMSprop(lr=0.005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def wide_model(seq_length, n_chars):\n",
    "    print('building one-layer model with 256 memory units...'.upper()+'\\n')\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(seq_length, n_chars)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "    optimizer = RMSprop(lr=0.005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def sample(probs, method=0):\n",
    "    probs = np.asarray(probs).astype('float64')\n",
    "    probs = probs/np.sum(probs)\n",
    "    \n",
    "    # helper function to sample an index from a probability array\n",
    "    if method == 0: \n",
    "        # method 0: just return index of character with the highest probability\n",
    "        index = np.argmax(probs)\n",
    "    elif method == 1: \n",
    "        # method 1: draw a random number from 0 to 1, calculate the cumulative sum of the prediction vector.\n",
    "        # return the index of the first element in the cumulative sum greater than the random number\n",
    "        index = np.argwhere(np.cumsum(probs)>np.random.uniform())[0][0]\n",
    "    elif method == 2:\n",
    "        # method 2: draw an element from a multinomial distribution defined by the given probabilities\n",
    "        index = np.argmax(np.random.multinomial(1, probs, 1))\n",
    "    elif method == 3:\n",
    "        # method 3: emphasis larger probabilities and diminish smaller probabilities by doing a log transform\n",
    "        temperature = 0.5 # less than one increases differences between small and large probabilities\n",
    "        probs = np.log(probs) / temperature # same as method 2 with temperature = 1\n",
    "        probs = np.exp(probs) # undo log transform\n",
    "        probs = probs / np.sum(probs)\n",
    "        index = np.argmax(np.random.multinomial(1, probs, 1))\n",
    "        \n",
    "    return index\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    if (epoch)%10 == 0:\n",
    "\n",
    "        print('\\nGENERATING CHARACTER SEQUENCE AFTER EPOCH: {}\\n'.format(epoch+1))\n",
    "\n",
    "        start_index = random.randint(0, len_text - seq_length - 1)\n",
    "       \n",
    "        \n",
    "        seed = text[start_index: start_index + seq_length]\n",
    "        print('GENERATING WITH SEED:\\n\\n' + seed + '\\n')\n",
    "        \n",
    "        \n",
    "        print('MAX SAMPLING:\\n')\n",
    "        phrase = seed\n",
    "        generated = ''\n",
    "        generated += phrase\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(seq_length):\n",
    "            x_pred = np.zeros((1, seq_length, len_chars))\n",
    "            for t, char in enumerate(phrase):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            probs = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(probs, method=0)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            phrase = phrase[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print('\\n')\n",
    "        \n",
    "        print('PROBABILISTIC SAMPLING:\\n')\n",
    "        phrase = seed\n",
    "        generated = ''\n",
    "        generated += phrase\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(seq_length):\n",
    "            x_pred = np.zeros((1, seq_length, len_chars))\n",
    "            for t, char in enumerate(phrase):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            probs = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(probs, method=1)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            phrase = phrase[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDINNG TWO-LAYER MODEL WITH 128 MEMORY UNITS...\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128, 128)          85504     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 38)                4902      \n",
      "=================================================================\n",
      "Total params: 221,990\n",
      "Trainable params: 221,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Epoch 1/41\n",
      "31520/31520 [==============================] - 26s 822us/step - loss: 2.8128 - acc: 0.2198\n",
      "\n",
      "GENERATING CHARACTER SEQUENCE AFTER EPOCH: 1\n",
      "\n",
      "GENERATING WITH SEED:\n",
      "\n",
      "ow to divide the conquest of thy sight;\n",
      "mine eye my heart thy picture's sight would bar,\n",
      "my heart mine eye the freedom of that r\n",
      "\n",
      "MAX SAMPLING:\n",
      "\n",
      "ow to divide the conquest of thy sight;\n",
      "mine eye my heart thy picture's sight would bar,\n",
      "my heart mine eye the freedom of that rethes theth thethes on theus theth thethes on theus theth thethes on theus theth thethes on theus theth thethes on theus theth t\n",
      "\n",
      "PROBABILISTIC SAMPLING:\n",
      "\n",
      "ow to divide the conquest of thy sight;\n",
      "mine eye my heart thy picture's sight would bar,\n",
      "my heart mine eye the freedom of that reore\n",
      "leke iveth;\n",
      "in heulxlfoliotheeg,\n",
      "havew roverssg tithongave\n",
      "wavevedud nno..r,\n",
      "\n",
      "ore ninc syres so oftaeghelg'huilhe ai'wy maw\n",
      "\n",
      "Epoch 2/41\n",
      "31520/31520 [==============================] - 25s 789us/step - loss: 2.2201 - acc: 0.3526\n",
      "Epoch 3/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 2.0135 - acc: 0.4003\n",
      "Epoch 4/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 1.8846 - acc: 0.4319\n",
      "Epoch 5/41\n",
      "31520/31520 [==============================] - 25s 789us/step - loss: 1.7842 - acc: 0.4610\n",
      "Epoch 6/41\n",
      "31520/31520 [==============================] - 25s 788us/step - loss: 1.6948 - acc: 0.4846\n",
      "Epoch 7/41\n",
      "31520/31520 [==============================] - 25s 789us/step - loss: 1.6206 - acc: 0.5015\n",
      "Epoch 8/41\n",
      "31520/31520 [==============================] - 25s 789us/step - loss: 1.5391 - acc: 0.5253\n",
      "Epoch 9/41\n",
      "31520/31520 [==============================] - 25s 789us/step - loss: 1.4612 - acc: 0.5439\n",
      "Epoch 10/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 1.3905 - acc: 0.5626\n",
      "Epoch 11/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 1.3090 - acc: 0.5857\n",
      "\n",
      "GENERATING CHARACTER SEQUENCE AFTER EPOCH: 11\n",
      "\n",
      "GENERATING WITH SEED:\n",
      "\n",
      "ou,\n",
      "drink up the monarch's plague, this flattery?\n",
      "or whether shall i say, mine eye saith true,\n",
      "and that your love taught it this\n",
      "\n",
      "MAX SAMPLING:\n",
      "\n",
      "ou,\n",
      "drink up the monarch's plague, this flattery?\n",
      "or whether shall i say, mine eye saith true,\n",
      "and that your love taught it this part with the will,\n",
      "that whose beauty thou will those thou shall be the world be the world be the world,\n",
      "and thou worth thou wi\n",
      "\n",
      "PROBABILISTIC SAMPLING:\n",
      "\n",
      "ou,\n",
      "drink up the monarch's plague, this flattery?\n",
      "or whether shall i say, mine eye saith true,\n",
      "and that your love taught it this wirdow shate,\n",
      "coom fars goust thou fire'st unfeety stamy fabed and morthesh so eye\n",
      "as were most all bars doth i graw, that wird\n",
      "\n",
      "Epoch 12/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 1.2360 - acc: 0.6052\n",
      "Epoch 13/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 1.1543 - acc: 0.6310\n",
      "Epoch 14/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 1.0840 - acc: 0.6512\n",
      "Epoch 15/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 1.0112 - acc: 0.6752\n",
      "Epoch 16/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 0.9444 - acc: 0.6964\n",
      "Epoch 17/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 0.8808 - acc: 0.7172\n",
      "Epoch 18/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 0.8226 - acc: 0.7333\n",
      "Epoch 19/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 0.7713 - acc: 0.7541\n",
      "Epoch 20/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 0.7239 - acc: 0.7657\n",
      "Epoch 21/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.6783 - acc: 0.78091s - loss: 0.6753 - acc:\n",
      "\n",
      "GENERATING CHARACTER SEQUENCE AFTER EPOCH: 21\n",
      "\n",
      "GENERATING WITH SEED:\n",
      "\n",
      "ge your day of youth to sullied night,\n",
      "and all in war with time for love of you,\n",
      "as he takes from you, i engraft you new.\n",
      "xvi\n",
      "bu\n",
      "\n",
      "MAX SAMPLING:\n",
      "\n",
      "ge your day of youth to sullied night,\n",
      "and all in war with time for love of you,\n",
      "as he takes from you, i engraft you new.\n",
      "xvi\n",
      "but that thou shalt be the world bad, that thou shell dear where brows,\n",
      "and that thou art the ster live, repure,\n",
      "then behing shave\n",
      "\n",
      "PROBABILISTIC SAMPLING:\n",
      "\n",
      "ge your day of youth to sullied night,\n",
      "and all in war with time for love of you,\n",
      "as he takes from you, i engraft you new.\n",
      "xvi\n",
      "but that thou art, beancy that be receed me ast,\n",
      "nove thou best, ere is deth they word that her kwild.\n",
      "xxxiv\n",
      "i mine, and that all'\n",
      "\n",
      "Epoch 22/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.6389 - acc: 0.79075s -\n",
      "Epoch 23/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 0.6029 - acc: 0.8006\n",
      "Epoch 24/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 0.5693 - acc: 0.81425\n",
      "Epoch 25/41\n",
      "31520/31520 [==============================] - 25s 788us/step - loss: 0.5484 - acc: 0.8176\n",
      "Epoch 26/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.5144 - acc: 0.8313\n",
      "Epoch 27/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 0.4908 - acc: 0.8383\n",
      "Epoch 28/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.4728 - acc: 0.8437\n",
      "Epoch 29/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.4535 - acc: 0.8496\n",
      "Epoch 30/41\n",
      "31520/31520 [==============================] - 25s 789us/step - loss: 0.4460 - acc: 0.8508\n",
      "Epoch 31/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 0.4252 - acc: 0.8576\n",
      "\n",
      "GENERATING CHARACTER SEQUENCE AFTER EPOCH: 31\n",
      "\n",
      "GENERATING WITH SEED:\n",
      "\n",
      " in war with time for love of you,\n",
      "as he takes from you, i engraft you new.\n",
      "xvi\n",
      "but wherefore do not you a mightier way\n",
      "make war\n",
      "\n",
      "MAX SAMPLING:\n",
      "\n",
      " in war with time for love of you,\n",
      "as he takes from you, i engraft you new.\n",
      "xvi\n",
      "but wherefore do not you a mightier way\n",
      "make ward, and shows to my preise.\n",
      "ncving thee she thy flame show my unurett.\n",
      "coull be the world beather party sines,\n",
      "to crows thou she \n",
      "\n",
      "PROBABILISTIC SAMPLING:\n",
      "\n",
      " in war with time for love of you,\n",
      "as he takes from you, i engraft you new.\n",
      "xvi\n",
      "but wherefore do not you a mightier way\n",
      "make ward, and show my bow'd,\n",
      "that sone bad,en thy powes defirt,\n",
      "so fo love sweetery with look'd on thee.\n",
      "xxxiii\n",
      "for my swill me then th\n",
      "\n",
      "Epoch 32/41\n",
      "31520/31520 [==============================] - 25s 789us/step - loss: 0.4101 - acc: 0.8634\n",
      "Epoch 33/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 0.4025 - acc: 0.8659\n",
      "Epoch 34/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.3913 - acc: 0.8697\n",
      "Epoch 35/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.3809 - acc: 0.8729\n",
      "Epoch 36/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.3768 - acc: 0.8758\n",
      "Epoch 37/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.3619 - acc: 0.8785\n",
      "Epoch 38/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.3498 - acc: 0.8831\n",
      "Epoch 39/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.3547 - acc: 0.8808\n",
      "Epoch 40/41\n",
      "31520/31520 [==============================] - 25s 791us/step - loss: 0.3487 - acc: 0.8828\n",
      "Epoch 41/41\n",
      "31520/31520 [==============================] - 25s 790us/step - loss: 0.3351 - acc: 0.8855\n",
      "\n",
      "GENERATING CHARACTER SEQUENCE AFTER EPOCH: 41\n",
      "\n",
      "GENERATING WITH SEED:\n",
      "\n",
      " rightly do inherit heaven's graces,\n",
      "and husband nature's riches from expense;\n",
      "they are the lords and owners of their faces,\n",
      "oth\n",
      "\n",
      "MAX SAMPLING:\n",
      "\n",
      " rightly do inherit heaven's graces,\n",
      "and husband nature's riches from expense;\n",
      "they are the lords and owners of their faces,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "others if if love sweet not the may,\n",
      "which i am the they are that i had with these,\n",
      "where as thy rack not besides but,\n",
      "they criftan\n",
      "\n",
      "PROBABILISTIC SAMPLING:\n",
      "\n",
      " rightly do inherit heaven's graces,\n",
      "and husband nature's riches from expense;\n",
      "they are the lords and owners of their faces,\n",
      "othince be fiers his she doth lime--\n",
      "and diel the feer cruen\n",
      "that be a gared thing end,\n",
      "so seal formen and should be in my vearn;\n",
      "t\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6adc7a750>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deeper, less wide, model\n",
    "model = deep_model(seq_length, len_chars)\n",
    "model.summary()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "print('\\n')\n",
    "model.fit(x, y,\n",
    "          batch_size=256,\n",
    "          epochs=41,\n",
    "          # epochs=21, # for frankenstein use fewer epochs because the text is much longer\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING ONE-LAYER MODEL WITH 256 MEMORY UNITS...\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 256)               302080    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 38)                9766      \n",
      "=================================================================\n",
      "Total params: 311,846\n",
      "Trainable params: 311,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Epoch 1/41\n",
      "31520/31520 [==============================] - 13s 405us/step - loss: 2.8310 - acc: 0.2103\n",
      "\n",
      "GENERATING CHARACTER SEQUENCE AFTER EPOCH: 1\n",
      "\n",
      "GENERATING WITH SEED:\n",
      "\n",
      "eir eyes were kind,\n",
      "to thy fair flower add the rank smell of weeds:\n",
      "but why thy odour matcheth not thy show,\n",
      "the soil is this, t\n",
      "\n",
      "MAX SAMPLING:\n",
      "\n",
      "eir eyes were kind,\n",
      "to thy fair flower add the rank smell of weeds:\n",
      "but why thy odour matcheth not thy show,\n",
      "the soil is this, thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue thaue tha\n",
      "\n",
      "PROBABILISTIC SAMPLING:\n",
      "\n",
      "eir eyes were kind,\n",
      "to thy fair flower add the rank smell of weeds:\n",
      "but why thy odour matcheth not thy show,\n",
      "the soil is this, thatedeieivmite.ist ii thian peeae liuae,\n",
      "uis antouaxugausuits\n",
      "eee eea,y:en iriseab.\n",
      "uutasxluge, ru ly heaur lariwcis dis inistye\n",
      "\n",
      "Epoch 2/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 2.2895 - acc: 0.3397\n",
      "Epoch 3/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 2.0898 - acc: 0.3833\n",
      "Epoch 4/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 1.9684 - acc: 0.4112\n",
      "Epoch 5/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 1.8771 - acc: 0.4346\n",
      "Epoch 6/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 1.7934 - acc: 0.4555\n",
      "Epoch 7/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 1.7201 - acc: 0.4732\n",
      "Epoch 8/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 1.6544 - acc: 0.4927\n",
      "Epoch 9/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 1.5918 - acc: 0.5094\n",
      "Epoch 10/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 1.5221 - acc: 0.5268\n",
      "Epoch 11/41\n",
      "31520/31520 [==============================] - 12s 390us/step - loss: 1.4549 - acc: 0.5435\n",
      "\n",
      "GENERATING CHARACTER SEQUENCE AFTER EPOCH: 11\n",
      "\n",
      "GENERATING WITH SEED:\n",
      "\n",
      "e long-liv'd phoenix, in her blood;\n",
      "make glad and sorry seasons as thou fleets,\n",
      "and do whate'er thou wilt, swift-footed time,\n",
      "to\n",
      "\n",
      "MAX SAMPLING:\n",
      "\n",
      "e long-liv'd phoenix, in her blood;\n",
      "make glad and sorry seasons as thou fleets,\n",
      "and do whate'er thou wilt, swift-footed time,\n",
      "to thee in my muse my self and my must my might,\n",
      "and thee spented dear fire, the will me mest my must my miget,\n",
      "so thine eye i suc\n",
      "\n",
      "PROBABILISTIC SAMPLING:\n",
      "\n",
      "e long-liv'd phoenix, in her blood;\n",
      "make glad and sorry seasons as thou fleets,\n",
      "and do whate'er thou wilt, swift-footed time,\n",
      "to faury and my rase, live; weras placiee edeigm\n",
      "ok love of thou, unoos t, and myself,\n",
      "of thou usheat sie i kingle sidge of rummen\n",
      "\n",
      "Epoch 12/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 1.3852 - acc: 0.5621\n",
      "Epoch 13/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 1.3247 - acc: 0.5808\n",
      "Epoch 14/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 1.2615 - acc: 0.6013\n",
      "Epoch 15/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 1.1889 - acc: 0.6182\n",
      "Epoch 16/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 1.1234 - acc: 0.6419\n",
      "Epoch 17/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 1.0970 - acc: 0.6552\n",
      "Epoch 18/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 1.0208 - acc: 0.6779\n",
      "Epoch 19/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.9601 - acc: 0.6918\n",
      "Epoch 20/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 1.1068 - acc: 0.6977\n",
      "Epoch 21/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.8748 - acc: 0.7172\n",
      "\n",
      "GENERATING CHARACTER SEQUENCE AFTER EPOCH: 21\n",
      "\n",
      "GENERATING WITH SEED:\n",
      "\n",
      "hee lie!\n",
      "thou art the grave where buried love doth live,\n",
      "hung with the trophies of my lovers gone,\n",
      "who all their parts of me to \n",
      "\n",
      "MAX SAMPLING:\n",
      "\n",
      "hee lie!\n",
      "thou art the grave where buried love doth live,\n",
      "hung with the trophies of my lovers gone,\n",
      "who all their parts of me to me, my lovely antill with my memper'd me.\n",
      "xxxxvii\n",
      "whe will will i what is the bestring make st me,\n",
      "make gall what is my jecture \n",
      "\n",
      "PROBABILISTIC SAMPLING:\n",
      "\n",
      "hee lie!\n",
      "thou art the grave where buried love doth live,\n",
      "hung with the trophies of my lovers gone,\n",
      "who all their parts of me to trourle sell belie,\n",
      "bay my must e child and meaking of the flound,\n",
      "than thou ants of love'd drad me that they?\n",
      "if i love sweetse\n",
      "\n",
      "Epoch 22/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.8375 - acc: 0.7291\n",
      "Epoch 23/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.8030 - acc: 0.7379\n",
      "Epoch 24/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.7709 - acc: 0.7461\n",
      "Epoch 25/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.7456 - acc: 0.7558\n",
      "Epoch 26/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.7180 - acc: 0.7649\n",
      "Epoch 27/41\n",
      "31520/31520 [==============================] - 12s 387us/step - loss: 0.6891 - acc: 0.7735\n",
      "Epoch 28/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 0.6723 - acc: 0.7787\n",
      "Epoch 29/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 0.6500 - acc: 0.7865\n",
      "Epoch 30/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.6322 - acc: 0.7912\n",
      "Epoch 31/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 0.6198 - acc: 0.7978\n",
      "\n",
      "GENERATING CHARACTER SEQUENCE AFTER EPOCH: 31\n",
      "\n",
      "GENERATING WITH SEED:\n",
      "\n",
      "ove in love's fresh case,\n",
      "weighs not the dust and injury of age,\n",
      "nor gives to necessary wrinkles place,\n",
      "but makes antiquity for \n",
      "\n",
      "MAX SAMPLING:\n",
      "\n",
      "ove in love's fresh case,\n",
      "weighs not the dust and injury of age,\n",
      "nor gives to necessary wrinkles place,\n",
      "but makes antiquity for a then benowell,\n",
      "and beauty hou, not this placke my brease,\n",
      "when i should gease sam slow?\n",
      "it it the world beauty see,\n",
      "that mysel\n",
      "\n",
      "PROBABILISTIC SAMPLING:\n",
      "\n",
      "ove in love's fresh case,\n",
      "weighs not the dust and injury of age,\n",
      "nor gives to necessary wrinkles place,\n",
      "but makes antiquity for a ther every woe.\n",
      "lxxxii\n",
      "shay my lifs within, like on inowience bousless'still'd,\n",
      "like a face, beauty good and heartleds sake,\n",
      "a\n",
      "\n",
      "Epoch 32/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 0.6078 - acc: 0.7979\n",
      "Epoch 33/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 0.5913 - acc: 0.8044\n",
      "Epoch 34/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 0.5722 - acc: 0.8118\n",
      "Epoch 35/41\n",
      "31520/31520 [==============================] - 12s 391us/step - loss: 0.5594 - acc: 0.8137\n",
      "Epoch 36/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.5616 - acc: 0.8128- ETA: 2s - l\n",
      "Epoch 37/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.5340 - acc: 0.8210\n",
      "Epoch 38/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.5352 - acc: 0.8192\n",
      "Epoch 39/41\n",
      "31520/31520 [==============================] - 12s 388us/step - loss: 0.5242 - acc: 0.8253\n",
      "Epoch 40/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 0.5196 - acc: 0.8290\n",
      "Epoch 41/41\n",
      "31520/31520 [==============================] - 12s 389us/step - loss: 0.5120 - acc: 0.8283\n",
      "\n",
      "GENERATING CHARACTER SEQUENCE AFTER EPOCH: 41\n",
      "\n",
      "GENERATING WITH SEED:\n",
      "\n",
      "ne\n",
      "may make seem bare, in wanting words to show it,\n",
      "but that i hope some good conceit of thine\n",
      "in thy soul's thought, all naked,\n",
      "\n",
      "MAX SAMPLING:\n",
      "\n",
      "ne\n",
      "may make seem bare, in wanting words to show it,\n",
      "but that i hope some good conceit of thine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in thy soul's thought, all naked, whils, and kindy,\n",
      "when thou still in this false in my cheross'd;\n",
      "and ther faret first masure of hours love,\n",
      "to the pligut the f\n",
      "\n",
      "PROBABILISTIC SAMPLING:\n",
      "\n",
      "ne\n",
      "may make seem bare, in wanting words to show it,\n",
      "but that i hope some good conceit of thine\n",
      "in thy soul's thought, all naked, thengh right'd was duemy't,\n",
      "to my shame dith art, who, cruch and coones,\n",
      "thou art, and roose shoul line,\n",
      "they in this sid, and \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6adc7a850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# less deep but wider model\n",
    "# deeper, less wide, model\n",
    "model = wide_model(seq_length, len_chars)\n",
    "model.summary()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "print('\\n')\n",
    "model.fit(x, y,\n",
    "          batch_size=256,\n",
    "          epochs=41,\n",
    "          # epochs=21, # for frankenstein use fewer epochs because the text is much longer\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
